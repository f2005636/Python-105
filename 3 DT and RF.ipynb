{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Desktop/python/03 advance/overfitting.csv')\n",
    "df = df.drop(['Target_Leaderboard','Target_Evaluate'],axis=1)\n",
    "train = df[df['train']==1]\n",
    "train = train.drop(['case_id','train'],axis=1)\n",
    "test = df[df['train']==0]\n",
    "test = test.drop(['case_id','train'],axis=1)\n",
    "y_train = train['Target_Practice']\n",
    "y_test = test['Target_Practice']\n",
    "x_train = train.drop(['Target_Practice'],axis=1)\n",
    "x_test = test.drop(['Target_Practice'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'criterion': ['entropy', 'gini'], 'splitter': ['best', 'random'], 'max_features': ['auto', 'log2'], 'max_leaf_nodes': [5, 10, 25, 50, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(criterion='entropy')\n",
    "paramgrid = {'criterion': [\"entropy\",\"gini\"], 'splitter': [\"best\",\"random\"], \n",
    "             'max_features': ['auto','log2'], 'max_leaf_nodes':[5,10,25,50,100,1000]} \n",
    "grid = GridSearchCV(dtree,param_grid=paramgrid,refit=True,verbose=4,cv=5,n_jobs=-1)\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 'log2', 'max_leaf_nodes': 10, 'splitter': 'random'}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features='log2', max_leaf_nodes=10,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random')\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = grid.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.31      0.39      9909\n",
      "          1       0.51      0.74      0.61      9841\n",
      "\n",
      "avg / total       0.53      0.52      0.50     19750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.522329113924\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[3052 6857]\n",
      " [2577 7264]]\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix\\n %s' % confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'criterion': ['entropy', 'gini'], 'max_features': ['auto', 'log2', 'sqrt'], 'max_leaf_nodes': [5, 10, 25, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcn=RandomForestClassifier(n_estimators=1000,oob_score=True,n_jobs=-1)\n",
    "paramgrid = {'criterion': [\"entropy\",\"gini\"], 'max_features': ['auto','log2','sqrt'], \n",
    "             'max_leaf_nodes':[5,10,25,50,100]} \n",
    "grid = GridSearchCV(rfcn,paramgrid,refit=True,n_jobs=-1,cv=10)\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_features': 'auto', 'max_leaf_nodes': 100}\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=100,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
      "            oob_score=True, random_state=None, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = grid.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.57      0.64      9909\n",
      "          1       0.65      0.80      0.72      9841\n",
      "\n",
      "avg / total       0.70      0.68      0.68     19750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.684\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[5613 4296]\n",
      " [1945 7896]]\n"
     ]
    }
   ],
   "source": [
    "print('confusion matrix\\n %s' % confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='log2', max_leaf_nodes=100,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000,oob_score=True,n_jobs=-1,\n",
    "                            max_leaf_nodes=100, criterion='gini', max_features='log2')\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 49 (0.012884)\n",
      "2. feature 177 (0.010923)\n",
      "3. feature 126 (0.010822)\n",
      "4. feature 39 (0.010404)\n",
      "5. feature 6 (0.009471)\n",
      "6. feature 125 (0.009157)\n",
      "7. feature 116 (0.009144)\n",
      "8. feature 87 (0.008376)\n",
      "9. feature 164 (0.008375)\n",
      "10. feature 115 (0.007867)\n",
      "11. feature 46 (0.007865)\n",
      "12. feature 160 (0.007806)\n",
      "13. feature 152 (0.007697)\n",
      "14. feature 147 (0.007669)\n",
      "15. feature 104 (0.007397)\n",
      "16. feature 118 (0.007247)\n",
      "17. feature 26 (0.007172)\n",
      "18. feature 173 (0.007135)\n",
      "19. feature 2 (0.007104)\n",
      "20. feature 189 (0.006933)\n",
      "21. feature 42 (0.006914)\n",
      "22. feature 53 (0.006882)\n",
      "23. feature 3 (0.006649)\n",
      "24. feature 157 (0.006534)\n",
      "25. feature 48 (0.006412)\n",
      "26. feature 127 (0.006339)\n",
      "27. feature 25 (0.006256)\n",
      "28. feature 198 (0.006226)\n",
      "29. feature 24 (0.006181)\n",
      "30. feature 108 (0.006159)\n",
      "31. feature 83 (0.006010)\n",
      "32. feature 38 (0.005998)\n",
      "33. feature 186 (0.005974)\n",
      "34. feature 196 (0.005945)\n",
      "35. feature 176 (0.005821)\n",
      "36. feature 145 (0.005820)\n",
      "37. feature 68 (0.005803)\n",
      "38. feature 133 (0.005802)\n",
      "39. feature 65 (0.005775)\n",
      "40. feature 34 (0.005739)\n",
      "41. feature 184 (0.005717)\n",
      "42. feature 194 (0.005673)\n",
      "43. feature 119 (0.005646)\n",
      "44. feature 98 (0.005562)\n",
      "45. feature 93 (0.005543)\n",
      "46. feature 0 (0.005537)\n",
      "47. feature 94 (0.005521)\n",
      "48. feature 101 (0.005520)\n",
      "49. feature 136 (0.005468)\n",
      "50. feature 79 (0.005434)\n",
      "51. feature 129 (0.005425)\n",
      "52. feature 138 (0.005377)\n",
      "53. feature 29 (0.005376)\n",
      "54. feature 56 (0.005344)\n",
      "55. feature 32 (0.005329)\n",
      "56. feature 134 (0.005303)\n",
      "57. feature 96 (0.005254)\n",
      "58. feature 78 (0.005216)\n",
      "59. feature 161 (0.005206)\n",
      "60. feature 158 (0.005169)\n",
      "61. feature 193 (0.005166)\n",
      "62. feature 114 (0.005142)\n",
      "63. feature 81 (0.005108)\n",
      "64. feature 151 (0.005107)\n",
      "65. feature 47 (0.005092)\n",
      "66. feature 122 (0.005000)\n",
      "67. feature 12 (0.004972)\n",
      "68. feature 175 (0.004969)\n",
      "69. feature 5 (0.004958)\n",
      "70. feature 159 (0.004949)\n",
      "71. feature 75 (0.004948)\n",
      "72. feature 182 (0.004912)\n",
      "73. feature 41 (0.004889)\n",
      "74. feature 103 (0.004887)\n",
      "75. feature 140 (0.004881)\n",
      "76. feature 9 (0.004881)\n",
      "77. feature 105 (0.004871)\n",
      "78. feature 190 (0.004862)\n",
      "79. feature 139 (0.004860)\n",
      "80. feature 120 (0.004814)\n",
      "81. feature 70 (0.004802)\n",
      "82. feature 28 (0.004794)\n",
      "83. feature 178 (0.004793)\n",
      "84. feature 135 (0.004785)\n",
      "85. feature 60 (0.004779)\n",
      "86. feature 107 (0.004755)\n",
      "87. feature 153 (0.004744)\n",
      "88. feature 1 (0.004727)\n",
      "89. feature 77 (0.004685)\n",
      "90. feature 8 (0.004675)\n",
      "91. feature 89 (0.004675)\n",
      "92. feature 61 (0.004670)\n",
      "93. feature 20 (0.004646)\n",
      "94. feature 50 (0.004645)\n",
      "95. feature 168 (0.004633)\n",
      "96. feature 191 (0.004631)\n",
      "97. feature 169 (0.004630)\n",
      "98. feature 74 (0.004623)\n",
      "99. feature 73 (0.004613)\n",
      "100. feature 130 (0.004595)\n",
      "101. feature 85 (0.004594)\n",
      "102. feature 112 (0.004569)\n",
      "103. feature 113 (0.004555)\n",
      "104. feature 156 (0.004552)\n",
      "105. feature 4 (0.004547)\n",
      "106. feature 45 (0.004539)\n",
      "107. feature 97 (0.004504)\n",
      "108. feature 109 (0.004503)\n",
      "109. feature 35 (0.004500)\n",
      "110. feature 154 (0.004500)\n",
      "111. feature 66 (0.004476)\n",
      "112. feature 100 (0.004469)\n",
      "113. feature 52 (0.004469)\n",
      "114. feature 69 (0.004466)\n",
      "115. feature 124 (0.004441)\n",
      "116. feature 181 (0.004441)\n",
      "117. feature 121 (0.004441)\n",
      "118. feature 21 (0.004429)\n",
      "119. feature 131 (0.004427)\n",
      "120. feature 88 (0.004415)\n",
      "121. feature 80 (0.004396)\n",
      "122. feature 67 (0.004395)\n",
      "123. feature 91 (0.004394)\n",
      "124. feature 23 (0.004344)\n",
      "125. feature 162 (0.004344)\n",
      "126. feature 51 (0.004335)\n",
      "127. feature 106 (0.004324)\n",
      "128. feature 172 (0.004306)\n",
      "129. feature 11 (0.004299)\n",
      "130. feature 111 (0.004291)\n",
      "131. feature 82 (0.004277)\n",
      "132. feature 132 (0.004274)\n",
      "133. feature 128 (0.004272)\n",
      "134. feature 167 (0.004262)\n",
      "135. feature 171 (0.004239)\n",
      "136. feature 44 (0.004238)\n",
      "137. feature 10 (0.004214)\n",
      "138. feature 95 (0.004206)\n",
      "139. feature 143 (0.004190)\n",
      "140. feature 13 (0.004186)\n",
      "141. feature 55 (0.004182)\n",
      "142. feature 59 (0.004178)\n",
      "143. feature 17 (0.004156)\n",
      "144. feature 19 (0.004146)\n",
      "145. feature 15 (0.004142)\n",
      "146. feature 141 (0.004128)\n",
      "147. feature 92 (0.004123)\n",
      "148. feature 99 (0.004109)\n",
      "149. feature 30 (0.004096)\n",
      "150. feature 72 (0.004093)\n",
      "151. feature 185 (0.004068)\n",
      "152. feature 195 (0.004067)\n",
      "153. feature 64 (0.004061)\n",
      "154. feature 37 (0.004060)\n",
      "155. feature 63 (0.004059)\n",
      "156. feature 146 (0.004043)\n",
      "157. feature 102 (0.004039)\n",
      "158. feature 86 (0.004027)\n",
      "159. feature 174 (0.004015)\n",
      "160. feature 110 (0.004008)\n",
      "161. feature 165 (0.003999)\n",
      "162. feature 71 (0.003980)\n",
      "163. feature 7 (0.003947)\n",
      "164. feature 18 (0.003942)\n",
      "165. feature 148 (0.003938)\n",
      "166. feature 149 (0.003924)\n",
      "167. feature 166 (0.003921)\n",
      "168. feature 188 (0.003908)\n",
      "169. feature 16 (0.003907)\n",
      "170. feature 187 (0.003864)\n",
      "171. feature 54 (0.003848)\n",
      "172. feature 90 (0.003836)\n",
      "173. feature 40 (0.003790)\n",
      "174. feature 84 (0.003785)\n",
      "175. feature 31 (0.003770)\n",
      "176. feature 76 (0.003741)\n",
      "177. feature 155 (0.003738)\n",
      "178. feature 144 (0.003735)\n",
      "179. feature 183 (0.003732)\n",
      "180. feature 180 (0.003730)\n",
      "181. feature 58 (0.003705)\n",
      "182. feature 199 (0.003688)\n",
      "183. feature 197 (0.003669)\n",
      "184. feature 43 (0.003648)\n",
      "185. feature 62 (0.003632)\n",
      "186. feature 192 (0.003604)\n",
      "187. feature 142 (0.003602)\n",
      "188. feature 163 (0.003577)\n",
      "189. feature 170 (0.003546)\n",
      "190. feature 33 (0.003526)\n",
      "191. feature 137 (0.003521)\n",
      "192. feature 117 (0.003432)\n",
      "193. feature 27 (0.003410)\n",
      "194. feature 123 (0.003384)\n",
      "195. feature 150 (0.003383)\n",
      "196. feature 22 (0.003356)\n",
      "197. feature 57 (0.003312)\n",
      "198. feature 14 (0.003119)\n",
      "199. feature 179 (0.003094)\n",
      "200. feature 36 (0.002857)\n"
     ]
    }
   ],
   "source": [
    "importances = rfc.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rfc.estimators_],axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
